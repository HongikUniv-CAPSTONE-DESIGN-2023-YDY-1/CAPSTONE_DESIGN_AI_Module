{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e551ab14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import functools\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# 라벨\n",
    "def read_xml_file(xml_file_path):\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "    labels = []\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def read_xml_and_add_labels(image_path, label_directory):\n",
    "    image_name = os.path.basename(image_path)\n",
    "    class_name = os.path.dirname(image_path).split(os.path.sep)[-1]\n",
    "    xml_file_path = os.path.join(label_directory, class_name, image_name[:-4] + '.xml')\n",
    "    labels = read_xml_file(xml_file_path)\n",
    "    return labels\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # 데이터증강기법\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=lambda img: tf.image.random_crop(img, [256, 256, 3])\n",
    "    )\n",
    "\n",
    "    # 훈련 데이터셋\n",
    "    train_directory = 'E:/종설/Training/1/[원천]면류'\n",
    "    train_label_directory = 'E:/종설/Training/2'\n",
    "    train_dataset = train_datagen.flow_from_directory(\n",
    "        train_directory,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=120,\n",
    "        shuffle=True,\n",
    "        seed=42,  # add a seed for reproducibility\n",
    "        follow_links=True,  # follow symbolic links if any\n",
    "        classes=None,  # set to None to use default class mode\n",
    "    )\n",
    "\n",
    "    # 훈련라벨\n",
    "    train_labels = []\n",
    "    for i, image_path in enumerate(train_dataset.filepaths):\n",
    "        labels = read_xml_and_add_labels(image_path, train_label_directory)\n",
    "        train_labels.append(labels)\n",
    "\n",
    "\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # 크기조정만\n",
    "    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "    )\n",
    "\n",
    "    # 검증데이터\n",
    "    val_directory = 'E:/종설/Validation/1/[원천]면류'\n",
    "    val_label_directory = 'E:/종설/Validation/2'\n",
    "    val_dataset = val_datagen.flow_from_directory(\n",
    "        val_directory,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=120,\n",
    "        shuffle=False,\n",
    "        classes=None,  # set to None to use default class mode\n",
    "    )\n",
    "\n",
    "    # 검증라벨\n",
    "    val_labels = []\n",
    "    for i, image_path in enumerate(val_dataset.filepaths):\n",
    "        labels = read_xml_and_add_labels(image_path, val_label_directory)\n",
    "        val_labels.append(labels)\n",
    "\n",
    "    val_labels = np.array(val_labels)\n",
    "\n",
    "    # EfficientNet-B0모델 불러오기\n",
    "    pretrained_model = hub.KerasLayer(\"C:/Users/sj990/MachineLearning/efficientnet_b0_feature-vector_1\", trainable=False)\n",
    "\n",
    "    # 층 추가\n",
    "    model = Sequential()\n",
    "    model.add(pretrained_model)\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(train_dataset.num_classes, activation='softmax', kernel_regularizer=l2(0.0003)))\n",
    "\n",
    "    # 컴파일 - 학습률조정\n",
    "    model.compile(\n",
    "        optimizer=RMSprop(lr=0.0005),  # Adam사용도 고려\n",
    "        loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    num_epochs = 50\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=val_dataset,\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    best_val_acc = max(history.history['val_accuracy'])\n",
    "    model.save('my_model_noodle_v3.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
