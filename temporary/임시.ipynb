{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7327061e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Found 23370 images belonging to 205 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sj990\\AppData\\Local\\Temp\\ipykernel_2528\\3239692883.py:78: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  train_labels = np.array(train_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3075 images belonging to 205 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sj990\\AppData\\Local\\Temp\\ipykernel_2528\\3239692883.py:101: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  val_labels = np.array(val_labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "183/183 [==============================] - 2288s 12s/step - loss: 5.6873 - accuracy: 0.0046 - val_loss: 5.3325 - val_accuracy: 0.0049\n",
      "Epoch 2/50\n",
      "183/183 [==============================] - 2425s 13s/step - loss: 5.3397 - accuracy: 0.0041 - val_loss: 5.3331 - val_accuracy: 0.0049\n",
      "Epoch 3/50\n",
      " 25/183 [===>..........................] - ETA: 25:06 - loss: 5.3376 - accuracy: 0.0060"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import functools\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# 라벨\n",
    "def read_xml_file(xml_file_path):\n",
    "    if not os.path.isfile(xml_file_path):\n",
    "        return []\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "    labels = []\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def read_xml_and_add_labels(image_path, label_directory):\n",
    "    if not os.path.isfile(image_path):\n",
    "        return []\n",
    "    image_name = os.path.basename(image_path)\n",
    "    class_name = os.path.dirname(image_path).split(os.path.sep)[-1]\n",
    "    xml_file_path = os.path.join(label_directory, class_name, image_name[:-4] + '.xml')\n",
    "    labels = read_xml_file(xml_file_path)\n",
    "    return labels\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "#매번바꿔주기\n",
    "num_classes = 205\n",
    "batch_size = 128\n",
    "\n",
    "initial_learning_rate = 0.048\n",
    "momentum = 0.9\n",
    "weight_decay = 0.00004\n",
    "dropout_rate = 0.2\n",
    "num_epochs = 50\n",
    "\n",
    "with strategy.scope():\n",
    "\n",
    "    # 데이터증강기법\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=lambda img: tf.image.random_crop(img, [256, 256, 3])\n",
    "    )\n",
    "\n",
    "    # 훈련 데이터셋\n",
    "    train_directory = 'E:/종설/Training/1/[원천]면류'\n",
    "    train_label_directory = 'E:/종설/Training/2'\n",
    "    train_dataset = train_datagen.flow_from_directory(\n",
    "        train_directory,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # 훈련라벨\n",
    "    train_labels = []\n",
    "    for i, image_path in enumerate(train_dataset.filepaths):\n",
    "        labels = read_xml_and_add_labels(image_path, train_label_directory)\n",
    "        train_labels.append(labels)\n",
    "\n",
    "\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    # 크기조정만\n",
    "    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1.0 / 255\n",
    "    )\n",
    "\n",
    "    # 검증데이터\n",
    "    val_directory = 'E:/종설/Validation/1/[원천]면류'\n",
    "    val_label_directory = 'E:/종설/Validation/2'\n",
    "    val_dataset = val_datagen.flow_from_directory(\n",
    "        val_directory,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # 검증라벨\n",
    "    val_labels = []\n",
    "    for i, image_path in enumerate(val_dataset.filepaths):\n",
    "        labels = read_xml_and_add_labels(image_path, val_label_directory)\n",
    "        val_labels.append(labels)\n",
    "\n",
    "    val_labels = np.array(val_labels)\n",
    "\n",
    "    # EfficientNet-B0모델 불러오기\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "\n",
    "    # Freeze the pre-trained layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    # 층 추가\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dropout(dropout_rate)(x)\n",
    "    predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    def lr_schedule(epoch):\n",
    "        initial_lr = initial_learning_rate\n",
    "        decay_factor = 0.97\n",
    "        decay_epochs = 2.4\n",
    "        lr = initial_lr * (decay_factor ** (epoch // decay_epochs))\n",
    "        return lr\n",
    "\n",
    "    # Define the optimizer with the learning rate schedule\n",
    "    optimizer = Adam(learning_rate=lr_schedule(0), beta_1=momentum, decay=weight_decay)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=len(train_dataset),\n",
    "        epochs=num_epochs,\n",
    "        callbacks=[lr_scheduler],\n",
    "        validation_data=val_dataset,\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    best_val_acc = max(history.history['val_accuracy'])\n",
    "    model.save('my_model_noodle_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedd50f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2518833a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a13d5d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d7e00125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Found 23370 images belonging to 205 classes.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '농심오징어짬뽕컵67G'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 66\u001b[0m\n\u001b[0;32m     54\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     55\u001b[0m     train_directory,\n\u001b[0;32m     56\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Set class_mode to None to return only the images without labels\u001b[39;00m\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     65\u001b[0m train_filepaths \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mfilepaths\n\u001b[1;32m---> 66\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m [read_xml_and_add_labels(image_path, train_label_directory) \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m train_filepaths]\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Find the maximum length of sequences in train_labels\u001b[39;00m\n\u001b[0;32m     69\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;28;01mfor\u001b[39;00m labels \u001b[38;5;129;01min\u001b[39;00m train_labels)\n",
      "Cell \u001b[1;32mIn[10], line 66\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     54\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m train_datagen\u001b[38;5;241m.\u001b[39mflow_from_directory(\n\u001b[0;32m     55\u001b[0m     train_directory,\n\u001b[0;32m     56\u001b[0m     target_size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     62\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Set class_mode to None to return only the images without labels\u001b[39;00m\n\u001b[0;32m     63\u001b[0m )\n\u001b[0;32m     65\u001b[0m train_filepaths \u001b[38;5;241m=\u001b[39m train_dataset\u001b[38;5;241m.\u001b[39mfilepaths\n\u001b[1;32m---> 66\u001b[0m train_labels \u001b[38;5;241m=\u001b[39m [\u001b[43mread_xml_and_add_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_directory\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m image_path \u001b[38;5;129;01min\u001b[39;00m train_filepaths]\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Find the maximum length of sequences in train_labels\u001b[39;00m\n\u001b[0;32m     69\u001b[0m max_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mlen\u001b[39m(labels) \u001b[38;5;28;01mfor\u001b[39;00m labels \u001b[38;5;129;01min\u001b[39;00m train_labels)\n",
      "Cell \u001b[1;32mIn[10], line 34\u001b[0m, in \u001b[0;36mread_xml_and_add_labels\u001b[1;34m(image_path, label_directory)\u001b[0m\n\u001b[0;32m     32\u001b[0m xml_file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(label_directory, class_name, image_name[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.xml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     33\u001b[0m labels \u001b[38;5;241m=\u001b[39m read_xml_file(xml_file_path)\n\u001b[1;32m---> 34\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint32\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to numpy array\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m labels\n",
      "\u001b[1;31mValueError\u001b[0m: invalid literal for int() with base 10: '농심오징어짬뽕컵67G'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import functools\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "# 라벨\n",
    "def read_xml_file(xml_file_path):\n",
    "    if not os.path.isfile(xml_file_path):\n",
    "        return []\n",
    "    tree = ET.parse(xml_file_path)\n",
    "    root = tree.getroot()\n",
    "    labels = []\n",
    "    for obj in root.findall('object'):\n",
    "        label = obj.find('name').text\n",
    "        labels.append(label)\n",
    "    return labels\n",
    "\n",
    "def read_xml_and_add_labels(image_path, label_directory):\n",
    "    if not os.path.isfile(image_path):\n",
    "        return []\n",
    "    image_name = os.path.basename(image_path)\n",
    "    class_name = os.path.dirname(image_path).split(os.path.sep)[-1]\n",
    "    xml_file_path = os.path.join(label_directory, class_name, image_name[:-4] + '.xml')\n",
    "    labels = read_xml_file(xml_file_path)\n",
    "    labels = np.array(labels, dtype=np.int32)  # Convert to numpy array\n",
    "    return labels\n",
    "\n",
    "\n",
    "with strategy.scope():\n",
    "    # 데이터증강기법\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.3,\n",
    "        height_shift_range=0.3,\n",
    "        shear_range=0.3,\n",
    "        zoom_range=0.3,\n",
    "        horizontal_flip=True,\n",
    "        preprocessing_function=lambda img: tf.image.random_crop(img, [256, 256, 3])\n",
    "    )\n",
    "\n",
    "    train_directory = 'E:/종설/Training/1/[원천]면류'\n",
    "    train_label_directory = 'E:/종설/Training/2'\n",
    "\n",
    "    train_dataset = train_datagen.flow_from_directory(\n",
    "        train_directory,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=120,\n",
    "        shuffle=True,\n",
    "        seed=42,\n",
    "        follow_links=True,\n",
    "        classes=None,\n",
    "        class_mode=None  # Set class_mode to None to return only the images without labels\n",
    "    )\n",
    "\n",
    "    train_filepaths = train_dataset.filepaths\n",
    "    train_labels = [read_xml_and_add_labels(image_path, train_label_directory) for image_path in train_filepaths]\n",
    "\n",
    "    # Find the maximum length of sequences in train_labels\n",
    "    max_length = max(len(labels) for labels in train_labels)\n",
    "\n",
    "    # Pad sequences in train_labels to the maximum length\n",
    "    train_labels = [labels + [0] * (max_length - len(labels)) for labels in train_labels]\n",
    "\n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_filepaths, train_labels))\n",
    "\n",
    "    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1./255\n",
    "    )\n",
    "\n",
    "    val_directory = 'E:/종설/Validation/1/[원천]면류'\n",
    "    val_label_directory = 'E:/종설/Validation/2'\n",
    "    val_dataset = val_datagen.flow_from_directory(\n",
    "        val_directory,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=120,\n",
    "        shuffle=False,\n",
    "        classes=None,\n",
    "        class_mode=None  # Set class_mode to None to return only the images without labels\n",
    "    )\n",
    "\n",
    "    val_filepaths = val_dataset.filepaths\n",
    "    val_labels = [read_xml_and_add_labels(image_path, val_label_directory) for image_path in val_filepaths]\n",
    "\n",
    "    # Pad sequences in val_labels to the maximum length\n",
    "    val_labels = [labels + [0] * (max_length - len(labels)) for labels in val_labels]\n",
    "\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_filepaths, val_labels))\n",
    "\n",
    "    \n",
    "    \n",
    "    # EfficientNet-B0모델 불러오기\n",
    "    pretrained_model = hub.KerasLayer(\"C:/Users/sj990/MachineLearning/efficientnet_b0_feature-vector_1\", trainable=False)\n",
    "\n",
    "    # Add Reshape layer to match input dimensions of GlobalAveragePooling2D\n",
    "    reshape_layer = tf.keras.layers.Reshape((1, 1, 1280))\n",
    "\n",
    "    # Add layers to the model\n",
    "    model = Sequential()\n",
    "    model.add(pretrained_model)\n",
    "    model.add(reshape_layer)\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(train_dataset.num_classes, activation='softmax', kernel_regularizer=l2(0.0005)))\n",
    "\n",
    "\n",
    "    def lr_schedule(epoch):\n",
    "        initial_lr = 0.0005\n",
    "        decay_factor = 0.97\n",
    "        decay_epochs = 2.4\n",
    "        lr = initial_lr * (decay_factor ** (epoch // decay_epochs))\n",
    "        return lr\n",
    "\n",
    "    # Define the optimizer with the learning rate schedule\n",
    "    optimizer = Adam(learning_rate=lr_schedule(0), beta_1=0.9, decay=0.0005)\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    num_epochs = 50\n",
    "    best_val_acc = 0.0\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        epochs=num_epochs,\n",
    "        validation_data=val_dataset,\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    best_val_acc = max(history.history['val_accuracy'])\n",
    "    model.save('my_model_noodle_v4.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac271a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd09a10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c0c05b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23370 images belonging to 205 classes.\n",
      "Found 3075 images belonging to 205 classes.\n",
      "Epoch 1/50\n",
      " 43/183 [======>.......................] - ETA: 25:05 - loss: 5.4408 - accuracy: 0.2470"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dropout, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import os\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "import functools\n",
    "from tensorflow.keras.optimizers import RMSprop, Adam\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "import pandas as pd\n",
    "\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "input_shape = (256, 256, 3)\n",
    "\n",
    "#매번바꿔주기\n",
    "num_classes = 205\n",
    "batch_size = 128\n",
    "\n",
    "initial_learning_rate = 0.048\n",
    "momentum = 0.9\n",
    "weight_decay = 0.00004\n",
    "dropout_rate = 0.2\n",
    "num_epochs = 50\n",
    "\n",
    "with strategy.scope():\n",
    "    \n",
    "    # 훈련 데이터셋\n",
    "    train_directory = 'E:/종설/Training/1/[원천]면류'\n",
    "    train_label_directory = 'E:/종설/Training/2'\n",
    "\n",
    "    # 데이터증강기법\n",
    "    train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1.0 / 255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest',\n",
    "        preprocessing_function=lambda img: tf.image.random_crop(img, [256, 256, 3])\n",
    "    )\n",
    "\n",
    "    train_dataset = train_datagen.flow_from_directory(\n",
    "        train_directory,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "    \n",
    "     # 검증데이터\n",
    "    val_directory = 'E:/종설/Validation/1/[원천]면류'\n",
    "    val_label_directory = 'E:/종설/Validation/2'\n",
    "    \n",
    "    # 크기조정만\n",
    "    val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        rescale=1.0 / 255\n",
    "    )\n",
    "\n",
    "    \n",
    "    val_dataset = val_datagen.flow_from_directory(\n",
    "        val_directory,\n",
    "        target_size=(256, 256),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "           \n",
    "    # EfficientNet-B0모델 불러오기\n",
    "    pretrained_model = hub.KerasLayer(\"C:/Users/sj990/MachineLearning/efficientnet_b0_feature-vector_1\")\n",
    "\n",
    "    # 층 추가\n",
    "    model = Sequential()\n",
    "    model.add(pretrained_model)\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(train_dataset.num_classes, activation='softmax', kernel_regularizer=l2(0.0005)))\n",
    "\n",
    "    # 동결\n",
    "    for layer in model.layers[:-1]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    def lr_schedule(epoch):\n",
    "        initial_lr = initial_learning_rate\n",
    "        decay_factor = 0.97\n",
    "        decay_epochs = 2.4\n",
    "        lr = initial_lr * (decay_factor ** (epoch // decay_epochs))\n",
    "        return lr\n",
    "\n",
    "    # Define the optimizer with the learning rate schedule\n",
    "    optimizer = Adam(learning_rate=lr_schedule(0), beta_1=momentum, decay=weight_decay)\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
    "\n",
    "    history = model.fit(\n",
    "        train_dataset,\n",
    "        steps_per_epoch=len(train_dataset),\n",
    "        epochs=num_epochs,\n",
    "        callbacks=[lr_scheduler],\n",
    "        validation_data=val_dataset, \n",
    "        validation_steps=len(val_dataset)\n",
    "    )\n",
    "\n",
    "    # Save the model\n",
    "    best_val_acc = max(history.history['val_accuracy'])\n",
    "    model.save('my_model_noodle_v4.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82287199",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b17d85c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "83d18308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'상품': '35161_농심)신라면큰사발면114G', '정확도': 0.98}]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "        \n",
    "# 1. 모델 불러오기\n",
    "model = tf.keras.models.load_model('my_model_noodle_v2.h5', custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "\n",
    "# 2. 이미지 불러오기(jpg or png파일형식)\n",
    "img_path = r'C:\\Users\\sj990\\Desktop\\ex\\shin.jpg'\n",
    "\n",
    "# 이미지전처리, 사이즈조정만\n",
    "img = tf.keras.preprocessing.image.load_img(img_path, target_size=(256, 256))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img = img.astype('float32') / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# 이미지 예측\n",
    "preds = model.predict(img)\n",
    "\n",
    "class_labels = []\n",
    "\n",
    "# 3. txt파일 불러오기\n",
    "with open('class_labels_noodle.txt', 'r') as file:\n",
    "    for line in file:\n",
    "        class_labels.append(line.strip())\n",
    "\n",
    "# 결과값 상위 3개\n",
    "top_preds_idx = preds[0].argsort()[ : : -1][ : 1]\n",
    "top_preds_labels = [class_labels[idx] for idx in top_preds_idx]\n",
    "top_preds_probs = preds[0][top_preds_idx]\n",
    "\n",
    "results = []\n",
    "\n",
    "#json형식 results\n",
    "for label, prob in zip(top_preds_labels, top_preds_probs):\n",
    "    result = {\n",
    "        '상품': label,\n",
    "        '정확도': round(float(prob), 2)\n",
    "    }\n",
    "    results.append(result)\n",
    "        \n",
    "\n",
    "#json파일 저장필요할시 사용\n",
    "with open('results.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(results, file, ensure_ascii=False)\n",
    "\n",
    "\n",
    "#출력예시\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5aa5039",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
