{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16787be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'상품': '35161_농심)신라면큰사발면114G', '정확도': 0.5}]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import glob     \n",
    "import json\n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "\n",
    "# 1. 모델 불러오기\n",
    "model = tf.keras.models.load_model(r'C:\\Users\\sj990\\MachineLearning\\CAPSTONE_DESIGN_AI_Module\\temporary\\면종류\\model_trained_in_NEURON_v2.h5', custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "\n",
    "# 경로설정\n",
    "image_directory = r'C:\\Users\\sj990\\Desktop\\ex3'\n",
    "\n",
    "# jpg, png, jpeg 형식 (리스트형식으로 저장된다, 경로에는 파일한장만 존재하게)\n",
    "image_files = glob.glob(image_directory + '/*.png') + glob.glob(image_directory + '/*.jpg') + glob.glob(image_directory + '/*.jpeg')\n",
    "\n",
    "# 리스트중 첫번째것만 사용\n",
    "image_path = image_files[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 이미지전처리, 사이즈조정만\n",
    "img = tf.keras.preprocessing.image.load_img(image_path, target_size=(256, 256))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img = img.astype('float32') / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# 이미지 예측\n",
    "preds = model.predict(img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class_labels = []\n",
    "\n",
    "# 3. txt파일 불러오기\n",
    "class_labels_path = r'C:\\Users\\sj990\\MachineLearning\\CAPSTONE_DESIGN_AI_Module\\temporary\\면종류\\class_labels_noodle.txt'\n",
    "\n",
    "with open(class_labels_path, 'r') as file:\n",
    "    for line in file:\n",
    "        class_labels.append(line.strip())\n",
    "\n",
    "\n",
    "# 결과값 상위 1개\n",
    "top_preds_idx = preds[0].argsort()[ : : -1][ : 1]\n",
    "top_preds_labels = [class_labels[idx] for idx in top_preds_idx]\n",
    "top_preds_probs = preds[0][top_preds_idx]\n",
    "\n",
    "results = []\n",
    "\n",
    "#json형식 results\n",
    "for label, prob in zip(top_preds_labels, top_preds_probs):\n",
    "    result = {\n",
    "        '상품': label,\n",
    "        '정확도': round(float(prob), 2)\n",
    "    }\n",
    "    results.append(result) \n",
    "\n",
    "\n",
    "#출력예시\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733d2b53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40503981",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ff1ca76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a811731c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "440359aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[51], line 70\u001b[0m\n\u001b[0;32m     67\u001b[0m top_preds_labels \u001b[38;5;241m=\u001b[39m [class_labels[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m top_preds_idx]\n\u001b[0;32m     68\u001b[0m top_preds_probs \u001b[38;5;241m=\u001b[39m preds[\u001b[38;5;241m0\u001b[39m][top_preds_idx]\n\u001b[1;32m---> 70\u001b[0m \u001b[43mtop_preds_labels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\n\u001b[0;32m     72\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m#json형식 results\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import glob     \n",
    "import json\n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "\n",
    "\n",
    "# 1. 모델 불러오기\n",
    "model = tf.keras.models.load_model(r'C:\\Users\\sj990\\MachineLearning\\CAPSTONE_DESIGN_AI_Module\\temporary\\미분류\\미분류모델.h5', custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "\n",
    "# 경로설정\n",
    "image_directory = r'C:\\Users\\sj990\\Desktop\\ex3'\n",
    "\n",
    "# jpg, png, jpeg 형식 (리스트형식으로 저장된다, 경로에는 파일한장만 존재하게)\n",
    "image_files = glob.glob(image_directory + '/*.png') + glob.glob(image_directory + '/*.jpg') + glob.glob(image_directory + '/*.jpeg')\n",
    "\n",
    "# 리스트중 첫번째것만 사용\n",
    "image_path = image_files[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 이미지전처리, 사이즈조정만\n",
    "img = tf.keras.preprocessing.image.load_img(image_path, target_size=(256, 256))\n",
    "img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "img = img.astype('float32') / 255.0\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# 이미지 예측\n",
    "preds = model.predict(img)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class_labels = []\n",
    "\n",
    "# 3. txt파일 불러오기\n",
    "class_labels_path = r'C:\\Users\\sj990\\MachineLearning\\CAPSTONE_DESIGN_AI_Module\\temporary\\미분류\\미분류라벨.txt'\n",
    "\n",
    "with open(class_labels_path, 'r') as file:\n",
    "    for line in file:\n",
    "        class_labels.append(line.strip())\n",
    "\n",
    "\n",
    "# 결과값 상위 1개\n",
    "top_preds_idx = preds[0].argsort()[ : : -1][ : 1]\n",
    "top_preds_labels = [class_labels[idx] for idx in top_preds_idx]\n",
    "top_preds_probs = preds[0][top_preds_idx]\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "#json형식 results\n",
    "for label, prob in zip(top_preds_labels, top_preds_probs):\n",
    "    result = {\n",
    "        '상품': label,\n",
    "        '정확도': round(float(prob), 2)\n",
    "    }\n",
    "    results.append(result)\n",
    "        \n",
    "        \n",
    "'''\n",
    "# json파일 저장필요할시 주석 제거후 사용\n",
    "with open('results.json', 'w', encoding='utf-8') as file:\n",
    "    json.dump(results, file, ensure_ascii=False)\n",
    "'''\n",
    "\n",
    "\n",
    "#출력예시\n",
    "print(results)\n",
    "\n",
    "'''\n",
    "# 사용한 이미지 파일 삭제 필요할시 주석 제거후 사용\n",
    "if results != None :\n",
    "    os.remove(image_path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752b799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "787c31c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55079_브레드가든푸드칼라아이싱칼라4종56G'] [0.97016495]\n",
      "['55079_브레드가든푸드칼라아이싱칼라4종56G'] [0.9779309]\n",
      "['55079_브레드가든푸드칼라아이싱칼라4종56G'] [0.9063979]\n",
      "['55079_브레드가든푸드칼라아이싱칼라4종56G'] [0.81161284]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013312670C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013312670C10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55079_브레드가든푸드칼라아이싱칼라4종56G'] [0.91311026]\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001337E043B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000001337E043B80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55079_브레드가든푸드칼라아이싱칼라4종56G'] [0.8465679]\n",
      "['55079_브레드가든푸드칼라아이싱칼라4종56G'] [0.39568365]\n",
      "['55079_브레드가든푸드칼라아이싱칼라4종56G'] [0.83672315]\n",
      "['55079_브레드가든푸드칼라아이싱칼라4종56G'] [0.9544029]\n",
      "['55079_브레드가든푸드칼라아이싱칼라4종56G'] [0.8584006]\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55041_농심짜왕큰사발면'] [0.99294996]\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55041_농심짜왕큰사발면'] [0.99294996]\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55041_농심짜왕큰사발면'] [0.99294996]\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55041_농심짜왕큰사발면'] [0.99294996]\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55041_농심짜왕큰사발면'] [0.99294996]\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55041_농심짜왕큰사발면'] [0.99294996]\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55041_농심짜왕큰사발면'] [0.99294996]\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55041_농심짜왕큰사발면'] [0.99294996]\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55041_농심짜왕큰사발면'] [0.99294996]\n",
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['55041_농심짜왕큰사발면'] [0.99294996]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import numpy as np\n",
    "import glob     \n",
    "import json\n",
    "import os\n",
    "from PIL import Image, ImageFilter\n",
    "from skimage import exposure\n",
    "\n",
    "class Model:\n",
    "    # 초기화\n",
    "    def __init__(self, img_path, model_path, class_labels_path):\n",
    "        self.img_path = img_path\n",
    "        self.model_path = model_path\n",
    "        self.class_labels_path = class_labels_path\n",
    "        \n",
    "        image_directory = img_path\n",
    "        # jpg, png, jpeg 형식 (리스트형식으로 저장된다, 경로에는 파일한장만 존재하게)\n",
    "        image_files = glob.glob(image_directory + '/*.png') + glob.glob(image_directory + '/*.jpg') + glob.glob(image_directory + '/*.jpeg')\n",
    "        # 리스트중 첫번째것만 사용\n",
    "        self.image_path = image_files[0]\n",
    "        \n",
    "        \n",
    "    #예측 (전처리된이미지와 클래스라벨을 삽입)\n",
    "    def preds_model(self, img, class_labels):\n",
    "        model = tf.keras.models.load_model(self.model_path,  custom_objects={'KerasLayer': hub.KerasLayer})\n",
    "        preds = model.predict(img) \n",
    "        \n",
    "        # 결과값 상위 1개\n",
    "        top_preds_idx = preds[0].argsort()[ : : -1][ : 1]\n",
    "        top_preds_labels = [class_labels[idx] for idx in top_preds_idx]\n",
    "        top_preds_probs = preds[0][top_preds_idx]\n",
    "        print(top_preds_labels, top_preds_probs)\n",
    "    \n",
    "    #이미지전처리_1 (기본)\n",
    "    def img_pre_default(self):  \n",
    "        img = tf.keras.preprocessing.image.load_img(self.image_path, target_size=(256, 256))\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img = img.astype('float32') / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "    \n",
    "    #이미지전처리_2 (가우시안)\n",
    "    def img_pre_gaussian(self): \n",
    "        img = Image.open(self.image_path)\n",
    "        img = img.filter(ImageFilter.GaussianBlur(radius=4))\n",
    "        img = img.resize((256, 256))\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img = img.astype('float32') / 255.0\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "    \n",
    "    #이미지전처리_3 (히스토그램 평활화)\n",
    "    def img_pre_hist(self):\n",
    "        img = tf.keras.preprocessing.image.load_img(self.image_path, target_size=(256, 256))\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img = img.astype('float32') / 255.0\n",
    "        img = exposure.equalize_hist(img)\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "    \n",
    "    #전처리4\n",
    "    def img_pre_augmentation(self): \n",
    "        img = tf.keras.preprocessing.image.load_img(self.image_path, target_size=(256, 256))\n",
    "        img = tf.keras.preprocessing.image.img_to_array(img)\n",
    "        img = img.astype('float32') / 255.0\n",
    "        \n",
    "        # 데이터 증강을 위한 ImageDataGenerator 생성\n",
    "        train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            rescale=1.0 / 255,\n",
    "            rotation_range=40,\n",
    "            width_shift_range=0.4,\n",
    "            height_shift_range=0.4,\n",
    "            shear_range=0.4,\n",
    "            zoom_range=0.4,\n",
    "            horizontal_flip=True,\n",
    "            preprocessing_function=lambda img: tf.image.random_crop(img, [256, 256, 3])\n",
    "        )\n",
    "        \n",
    "        # 데이터 증강 적용\n",
    "        img = train_datagen.random_transform(img)\n",
    "        \n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    #라벨불러오기\n",
    "    def class_label(self):\n",
    "        class_labels = []\n",
    "        with open(self.class_labels_path, 'r') as file:\n",
    "            for line in file:\n",
    "                class_labels.append(line.strip())\n",
    "        return class_labels\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "model1 = Model(r'C:\\Users\\sj990\\Desktop\\ex3',\n",
    "               r'C:\\Users\\sj990\\MachineLearning\\CAPSTONE_DESIGN_AI_Module\\temporary\\미분류\\미분류모델.h5',\n",
    "               r'C:\\Users\\sj990\\MachineLearning\\CAPSTONE_DESIGN_AI_Module\\temporary\\미분류\\미분류라벨.txt')\n",
    "\n",
    "model2 = Model(r'C:\\Users\\sj990\\Desktop\\ex3',\n",
    "               r'C:\\Users\\sj990\\MachineLearning\\CAPSTONE_DESIGN_AI_Module\\temporary\\면종류\\model_trained_in_NEURON_v2.h5',\n",
    "               r'C:\\Users\\sj990\\MachineLearning\\CAPSTONE_DESIGN_AI_Module\\temporary\\면종류\\class_labels_noodle.txt')\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "class_labels_1 = model1.class_label()\n",
    "\n",
    "for i in range(10):\n",
    "    model1_pre_img = model1.img_pre_augmentation()\n",
    "    result4 = model1.preds_model(model1_pre_img, class_labels_1)\n",
    "\n",
    "\"\"\"\n",
    "model1_default_img = model1.img_pre_default()\n",
    "model1_gaussian_img = model1.img_pre_gaussian()\n",
    "model1_hist_img = model1.img_pre_hist()\n",
    "model1_pre_img = model1.img_pre_augmentation()\n",
    "\n",
    "result1 = model1.preds_model(model1_default_img, class_labels)\n",
    "result2 = model1.preds_model(model1_gaussian_img, class_labels)\n",
    "result3 = model1.preds_model(model1_hist_img, class_labels)\n",
    "result4 = model1.preds_model(model1_pre_img, class_labels)\n",
    "\"\"\"     \n",
    "    \n",
    "\n",
    "class_labels_2 = model2.class_label()\n",
    "\"\"\"\n",
    "model2_default_img = model2.img_pre_default()\n",
    "model2_gaussian_img = model2.img_pre_gaussian()\n",
    "model2_hist_img = model2.img_pre_hist()\n",
    "model2_pre_img = model2.img_pre_augmentation()\n",
    "\n",
    "result1 = model2.preds_model(model2_default_img, class_labels)\n",
    "result2 = model2.preds_model(model2_gaussian_img, class_labels)\n",
    "result3 = model2.preds_model(model2_hist_img, class_labels)\n",
    "result4 = model2.preds_model(model2_pre_img, class_labels)\n",
    "\"\"\"\n",
    "\n",
    "for i in range(10):\n",
    "    model2_pre_img = model2.img_pre_augmentation()\n",
    "    result4 = model2.preds_model(model1_pre_img, class_labels_2)    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879b691",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_gpu",
   "language": "python",
   "name": "tf_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
